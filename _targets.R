library(targets)
library(tarchetypes)
source("R/packages.R")
source("R/functions.R")

# Specify path to folder with raw data
data_raw <- "_targets/user/data_raw"

# Specify location of intermediate results file
int_dir <- "_targets/user/intermediates"

# Set parallel back-end
plan(callr)

# Set options:
# - Use targets workspaces for debugging
# - Track dependencies in some packages
tar_option_set(
  workspace_on_error = TRUE,
  # FIXME: add {pteridocat} as import when it is live
  imports = c("taxastand")
  )

tar_plan(
  # Load data ----
  # FIXME: temporary work-around for loading pteridocat data
  # until {pteridocat} package is live
  tar_file(pteridocat_file, path(data_raw, "pteridocat.RDS")),
  pteridocat = readRDS(pteridocat_file),
  # Modified PPGI taxonomy
  # with new genera and slightly different treatments following World Ferns list
  tar_file(
    ppgi_taxonomy_path,
    path(data_raw, "ppgi_taxonomy_mod.csv")),
  ppgi_taxonomy = read_csv(ppgi_taxonomy_path),
  # Equisetum subgenus level taxonomy
  tar_file(equisteum_subgen_path, path(data_raw, "equisetum_subgenera.csv")),
  # List of coding genes to extract from plastomes
  # (based on genes of Wei et al 2017, then trimmed to non-duplicated genes)
  tar_file(
    target_plastome_genes_path,
    path(data_raw, "target_coding_genes.txt")),
  target_plastome_genes = read_lines(target_plastome_genes_path),
  # Outgroup plastome accessions
  # (Some species names later get updated in plastome_metadata_renamed due to
  # pulling most recent taxonomy from NCBI)
  tar_file(
    plastome_outgroups_path,
    path(data_raw, "plastome_outgroups.csv")),
  plastome_outgroups = read_csv(plastome_outgroups_path),
  # Manually curated list of GenBank accessions to exclude from analysis
  tar_file(
    accs_exclude_path,
    path(data_raw, "accs_exclude.csv")),
  accs_exclude = read_csv(accs_exclude_path),
  # Reference alignments for assembling genes
  # generated by prep_ref_seqs_plan.R
  tar_file(
    ref_aln_files,
    list.files(
      path(data_raw, "ref_aln"),
      pattern = "\\.fasta",
      full.names = TRUE)
  ),
  fern_ref_seqs = load_ref_aln(ref_aln_files),
  # NCBI taxonomic database
  # downloaded from
  # https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump_archive/taxdmp_2022-02-01.zip #nolint
  tar_file(taxdump_zip_file, path(data_raw, "taxdmp_2022-02-01.zip")),
  # Fossil calibration points
  tar_file(
    fossil_dates_path,
    path(data_raw, "Fossils_Ferns.csv")
  ),

  # Prep for assembling Sanger plastid regions ----
  # Define variables used in plan:
  # - Target plastid loci (coding genes and spacers)
  target_loci = c(
    "atpA", "atpB", "matK", "rbcL", "rps4",
    "trnL-trnF", "rps4-trnS"),
  # - Target spacers only
  target_spacers = target_loci[str_detect(target_loci, "-")],
  # - Target plastome loci (full set of plastome genes plus spacers)
  target_plastome_loci = c(target_plastome_genes, target_spacers),
  # - Most recent date cutoff for sampling genes
  date_cutoff = "2021/12/31",

  # Download and extract Sanger sequences ----
  # Download raw fasta files
  tar_target(
    fern_sanger_seqs_raw,
    fetch_fern_sanger_seqs(
      target_loci,
      end_date = date_cutoff),
    pattern = map(target_loci),
    # don't run in parallel, or will get HTTP status 429 errors
    deployment = "main"
  ),
  # Extract target regions with superCRUNCH
  tar_target(
    fern_sanger_extract_res,
    extract_from_ref_blast(
      # Drop excluded sequences
      query_seqtbl = fern_sanger_seqs_raw,
      ref_seqtbl = fern_ref_seqs,
      target = target_loci,
      blast_flavor = "dc-megablast",
      other_args = c("-m", "span", "--threads", "4")
    ),
    pattern = map(target_loci)
  ),
  raw_fasta_all = clean_extract_res(fern_sanger_extract_res, "dc-megablast"),
  # Drop excluded sequences
  raw_fasta = anti_join(raw_fasta_all, accs_exclude, by = "accession"),
  # Fetch metadata
  tar_target(
    raw_meta_all,
    fetch_fern_metadata(
      target_loci,
      end_date = date_cutoff),
    pattern = map(target_loci),
    deployment = "main"
  ),
  raw_meta = unique(raw_meta_all) %>%
    # Drop excluded sequences from metadata
    anti_join(accs_exclude, by = "accession"),

  # Resolve taxonomic names for Sanger sequences ----
  # Specify varieties to exclude from collapsing
  # during taxonomic name resolution
  varieties_to_keep = define_varieties_to_keep(),
  # Extract species names from NCBI taxonomic database
  tar_target(
    ncbi_names_raw,
    extract_ncbi_names(
      taxdump_zip_file, taxid_keep = raw_meta,
      names_exclude = ncbi_db_names_to_exclude(),
      workers = 20),
    deployment = "main"),
  # Clean NCBI species names
  ncbi_names_full = clean_ncbi_names(ncbi_names_raw),
  # Exclude invalid names (hybrids, taxa not identified to species level)
  ncbi_names_query = exclude_invalid_ncbi_names(ncbi_names_full),
  # Parse reference names
  pc_ref_names = ts_parse_names(
    unique(pteridocat$scientificName), tbl_out = TRUE, quiet = TRUE),
  # Resolve names, round 1: NCBI accepted scientific names
  ncbi_names_query_round_1 = select_ncbi_names_round_1(ncbi_names_query),
  # - match names to reference
  match_results_raw_round_1 = ts_match_names(
    query = ncbi_names_query_round_1$scientific_name,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE,
    match_canon = TRUE, collapse_infra = TRUE,
    collapse_infra_exclude = varieties_to_keep),
  # - resolve synonyms
  match_results_resolved_round_1 = ts_resolve_names(
    match_results_raw_round_1, pteridocat),
  # Resolve names, round 2: NCBI synonym scientific names
  ncbi_names_query_round_2 = select_ncbi_names_round_2(
    match_results_resolved_round_1, ncbi_names_query),
  match_results_raw_round_2 = ts_match_names(
    query = ncbi_names_query_round_2$scientific_name,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE,
    match_canon = TRUE, collapse_infra = TRUE,
    collapse_infra_exclude = varieties_to_keep),
  match_results_resolved_round_2 = ts_resolve_names(
    match_results_raw_round_2, pteridocat),
  # Resolve names, round 3: NCBI species without author
  ncbi_names_query_round_3 = select_ncbi_names_round_3(
    match_results_resolved_round_1,
    match_results_resolved_round_2, ncbi_names_query),
  match_results_raw_round_3 = ts_match_names(
    query = ncbi_names_query_round_3$species,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE,
    match_canon = TRUE, collapse_infra = TRUE,
    collapse_infra_exclude = varieties_to_keep),
  match_results_resolved_round_3 = ts_resolve_names(
    match_results_raw_round_3, pteridocat),
  # Combine name resolution results
  match_results_resolved_all =
    combined_match_results(
      ncbi_names_query = ncbi_names_query,
      match_results_resolved_round_1,
      match_results_resolved_round_2,
      match_results_resolved_round_3),
  # Map NCBI names to accepted names
  ncbi_accepted_names_map = make_ncbi_accepted_names_map(
    match_results_resolved_all),
  # Inspect name resolution results
  pterido_names_to_inspect = inspect_ts_results(match_results_resolved_all),

  # Remove rogues from Sanger sequences ----
  # Combine sanger sequences and metadata, filter to resolved names
  # - set minimum lengths (bp) for filtering genes and spacers
  min_gene_len = 200,
  min_spacer_len = 20,
  sanger_seqs_combined_filtered = combine_and_filter_sanger(
    raw_meta, raw_fasta, ncbi_accepted_names_map,
    ppgi_taxonomy, min_gene_len, min_spacer_len),
  # Make BLAST database including all fern sequences
  tar_file(
    sanger_blast_db,
    make_fern_blast_db(
      seqtbl = sanger_seqs_combined_filtered,
      blast_db_dir = path(int_dir, "blast_sanger"),
      out_name = "ferns_sanger")
  ),
  # Group query sequences for parallel computing
  tar_group_count(
    sanger_blast_query,
    dplyr::select(sanger_seqs_combined_filtered, seq, otu),
    count = 30), # number of jobs to run in parallel
  # Conduct all-by-all blast in parallel
  tar_target(
    all_by_all_blast,
    blast_seqtbl(
      seqtbl = sanger_blast_query,
      blastdb_files = sanger_blast_db
    ),
    pattern = map(sanger_blast_query)
  ),
  # Identify rogues (sequences matching wrong family)
  sanger_seqs_rogues = detect_rogues(
    metadata_with_seqs = sanger_seqs_combined_filtered,
    blast_results = all_by_all_blast,
    ppgi = ppgi_taxonomy),
  sanger_seqs_rogues_inspected = inspect_rogues(
    sanger_seqs_rogues,
    raw_meta_all,
    ncbi_names_query,
    ppgi_taxonomy),
  sanger_seqs_rogues_removed = anti_join(
    sanger_seqs_combined_filtered,
    sanger_seqs_rogues,
    by = c("accession", "target")
  ),

  # Check for species monophyly in Sanger loci ----
  # - split sequence tibble up by target loci
  tar_target(
    mpcheck_sliced,
    filter(sanger_seqs_rogues_removed, target == target_loci),
    pattern = map(target_loci)
  ),
  # - align each locus
  tar_target(
    mpcheck_aligned,
    align_seqs_tbl(mpcheck_sliced),
    pattern = map(mpcheck_sliced)
  ),
  # - trim each locus
  # 1% missing cutoff for spacers, 5% otherwise nolint
  # name by accession since includes multiple sequences per species
  mpcheck_trimmed = trim_genes(mpcheck_aligned, name_col_in = "accession"),
  # - build tree for each locus
  tar_target(
    mpcheck_tree,
    build_tree_from_alignment_df(mpcheck_trimmed, program = "fasttree"),
    pattern = map(mpcheck_trimmed)
  ),
  # - check monophyly
  tar_target(
    mpcheck_monophy,
    check_monophy(mpcheck_sliced, mpcheck_tree, workers = 32),
    pattern = map(mpcheck_sliced, mpcheck_tree),
    deployment = "main"
  ),

  # Select final Sanger sequences ----
  # First parse specimen voucher data
  sanger_seqs_with_voucher_data = parse_voucher(sanger_seqs_rogues_removed),
  # Join sequences across species, then select one set of sequences per species
  # Criteria for joining sequences across species:
  # - species is monophyletic, or
  # - all sequences for that species are from the same voucher, or
  # - all sequences for that species are from same publication
  # Criteria for selecting final set of sequences for each species (in order):
  # - 1: specimens with longest rbcL + any other gene
  # - 2: specimens with longest rbcL
  # - 3: specimens with longest combined non-rbcL genes
  # - 4: specimens with longest non-combined non-rbcL genes
  sanger_accessions_selection = select_genbank_genes(
    sanger_seqs_with_voucher_data, mpcheck_monophy),

  # Download core set of plastid genes from plastomes ----
  # Download plastome metadata (accessions and species)
  plastome_metadata_raw_all = download_plastome_metadata(
    end_date = date_cutoff,
    outgroups = plastome_outgroups),
  # Drop sequences to exclude
  plastome_metadata_raw = anti_join(
    plastome_metadata_raw_all,
    accs_exclude, by = "accession"
  ),
  # Extract species names in plastome data from NCBI taxonomy
   plastome_ncbi_names_raw = extract_ncbi_names(
     taxdump_zip_file, taxid_keep = plastome_metadata_raw,
     names_exclude = plastome_ncbi_db_names_to_exclude(),
     workers = 2),
  # Resolve species names in plastome metadata
  # (drops accession if name could not be resolved)
  plastome_metadata_renamed = resolve_pterido_plastome_names(
    plastome_ncbi_names_raw, plastome_metadata_raw, plastome_outgroups,
    pc_ref_names, pteridocat
  ),
  # Download plastome sequences
  # FASTA files for each accession in seqtbl format
  target_plastome_accessions = unique(plastome_metadata_renamed$accession),
  plastome_fasta = read_genbank(target_plastome_accessions),
  # Extract target genes and spacers with superCRUNCH
  tar_target(
    fern_plastome_loci_extract_res,
    extract_from_ref_blast(
      query_seqtbl = mutate(plastome_fasta, gene = target_plastome_loci),
      ref_seqtbl = fern_ref_seqs,
      target = target_plastome_loci,
      blast_flavor = "dc-megablast",
      other_args = c("-m", "span", "--threads", "4")
    ),
    pattern = map(target_plastome_loci)
  ),
  # Combine plastome metadata and sequences, filter to best accession per taxon
  plastome_seqs_combined_filtered = select_plastome_seqs(
    plastome_genes_raw,
    plastome_metadata_renamed,
    fern_plastome_loci_extract_res),

  # Align spacers ----
  # Assign taxonomic clusters (by family) for aligning spacer regions
  tar_target(
    plastid_spacers_unaligned,
    assign_tax_clusters(
      sanger_accessions_selection,
      sanger_seqs_combined_filtered,
      plastome_seqs_combined_filtered,
      ppgi_taxonomy, plastome_metadata_renamed,
      target_spacers
    ),
    pattern = map(target_spacers),
  ), # - configure groups for aligning in parallel
  tar_target(
    plastid_spacers_unaligned_grouped,
    plastid_spacers_unaligned %>%
      filter(cluster != "none") %>%
      group_by(target, cluster) %>%
      tar_group(),
    iteration = "group"
  ),
  # Align each cluster
  tar_target(
    plastid_spacers_aligned_clusters,
    align_seqs_tbl(plastid_spacers_unaligned_grouped),
    pattern = map(plastid_spacers_unaligned_grouped),
    iteration = "vector"
  ),
  # Trim each cluster, rename each sequence by taxon
  # (Use a very light threshold, to keep most gaps)
  plastid_spacers_aligned_trimmed_clusters = trim_spacers_by_cluster(
    plastid_spacers_aligned_clusters),
  # Also make overall alignment with one representative
  # per cluster to identify sequences needing reverse-complement
  tar_target(
    plastid_spacers_rep_align,
    align_rep_spacers(
      plastid_spacers_aligned_trimmed_clusters, # clusters
      plastid_spacers_unaligned, # singletons
      target_select = target_spacers,
      exclude_terms = "Anemiaceae"), # exclude Anemiaceae, too variable to align
    pattern = map(target_spacers)
  ),
  # Reverse-complement spacers
  plastid_spacers_aligned_trimmed_reversed_clusters = reverse_spacers(
    plastid_spacers_aligned_trimmed_clusters, plastid_spacers_rep_align
  ),
  # Merge subalignments
  tar_target(
    plastid_spacers_aligned_trimmed,
    merge_spacer_alignments(
      plastid_spacers_aligned_trimmed_reversed_clusters,
      n_threads = 10,
      target_select = target_spacers),
    pattern = map(target_spacers)
  ),

  # Align genes ----
  # Combine Sanger and plastome genes into single dataframe, group by gene
  tar_group_by(
    plastid_genes_unaligned,
    combine_sanger_plastome(
      # Exclude spacer regions (spacer regions have hyphen in name)
      sanger_accessions_selection %>%
        select(-contains("-")),
      sanger_seqs_combined_filtered %>%
        filter(str_detect(target, "-", negate = TRUE)),
      plastome_seqs_combined_filtered %>%
        filter(str_detect(target, "-", negate = TRUE))
      ),
    target),
  # Align sequences by gene
  tar_target(
    plastid_genes_aligned,
    align_seqs_tbl(plastid_genes_unaligned),
    pattern = map(plastid_genes_unaligned)
  ),
  # Trim alignments, rename each sequence by taxon
  plastid_genes_aligned_trimmed = trim_genes(plastid_genes_aligned),

  # Concatenate alignments ----
  # - tbl format
  sanger_alignment_tbl = concatenate_plastid_sanger(
    plastid_genes_aligned_trimmed,
    plastid_spacers_aligned_trimmed,
    target_loci, type_select = "sanger"
  ),
  plastome_alignment_tbl = concatenate_plastid_sanger(
    plastid_genes_aligned_trimmed,
    plastid_spacers_aligned_trimmed,
    target_loci, type_select = "plastome"
  ),
  # - ape format
  sanger_alignment = concatenate_to_ape(sanger_alignment_tbl),
  plastome_alignment = concatenate_to_ape(plastome_alignment_tbl),

  # Phylogenetic analysis ----
  # Backbone consensus tree
  tar_target(
    plastome_tree,
    iqtree(
      plastome_alignment,
      m = "MFP", # test model followed by ML analysis
      bb = 1000, nt = 12, seed = 20220123,
      redo = TRUE, echo = TRUE, wd = path(int_dir, "iqtree/plastome"),
      other_args = c(
        "-mset", "GTR", # only test GTR models
        "-mrate", "E,I,G,I+G", # don't test free-rate models
        "-t", "PARS"),
      tree_path = path(
        int_dir, "iqtree/plastome/plastome_alignment.phy.contree")
    ),
    deployment = "main"
  ),
  # collapse nodes with BS < 95, write out as constraint tree
  constraint_tree = di2multi4node(plastome_tree, 95),
  tar_file(
    constraint_tree_file,
    write_tree_tar(
      constraint_tree,
      path(int_dir, "iqtree/constraint.tre")
    )
  ),
  # Initial Sanger tree (fast mode)
  tar_target(
    sanger_tree_fast,
    iqtree(
      sanger_alignment,
      m = "GTR+I+G", nt = 6, seed = 20220129,
      redo = TRUE, echo = TRUE, wd = path(int_dir, "iqtree/sanger_fast"),
      other_args = c(
        "-fast",
        "-t", "PARS",
        "-alrt", "1000",
        "-g", path_abs(constraint_tree_file)
      )
    )
  ),
  # Final Sanger ML tree
  tar_target(
    sanger_ml_tree,
    iqtree(
      sanger_alignment,
      m = "MFP", bb = 1000, nt = 6, seed = 20220129,
      redo = TRUE, echo = TRUE, wd = path(int_dir, "iqtree/sanger"),
      other_args = c(
        "-mset", "GTR",
        "-mrate", "E,I,G,I+G",
        "-t", "PARS",
        "-g", path_abs(constraint_tree_file)
      ),
      # Return best ML tree and consensus
      tree_path = c(
        ml_tree = path(int_dir, "iqtree/sanger/sanger_alignment.phy.treefile"),
        con_tree = path(int_dir, "iqtree/sanger/sanger_alignment.phy.contree"),
      )
    )
  ),
  # Check monophyly ----
  # FIXME: use sanger_tree, not sanger_tree_fast, when ready
  # Root tree on bryophytes
  sanger_tree_rooted = phytools::reroot(
    sanger_tree_fast,
    getMRCA(sanger_tree_fast,
      c("Physcomitrium_patens", "Marchantia_polymorpha", "Anthoceros_angustus"))
  ),
  # Load Equisetum data (only group with subgenera in fossils)
  equisetum_subgen = load_equisetum_subgen(
    equisteum_subgen_path, sanger_tree_fast),
  # Define groups for checking monophyly
  taxa_levels_check = c(
    "order", "suborder", "family",
    "subfamily", "genus", "subgenus"),
  # Make tibble mapping species to putatively monophyletic groups
  sanger_sampling = make_sanger_sampling_tbl(
    plastome_metadata_renamed, sanger_alignment,
    sanger_tree = sanger_tree_fast,
    ppgi_taxonomy = ppgi_taxonomy) %>%
    # Add Equisetum subgenera
    left_join(equisetum_subgen, by = "species"),
  ,
  # Check monophyly
  mono_test = assess_monophy(
    taxon_sampling = sanger_sampling,
    tree = sanger_tree_rooted,
    tax_levels = taxa_levels_check
  ),
  monophy_by_clade = map_df(
    seq_along(taxa_levels_check),
    ~get_result_monophy(mono_test, .)
  ),
  # Dating prep ----
  # Load fossil calibration points
  fossil_calibration_points = load_fossil_calibration_points(fossil_dates_path),
  # Define some tips for spanning non-monophyletic groups
  manual_spanning_tips = define_manual_spanning_tips(),
  # Map species in the tree to their fossil groups
  fossil_node_species_map = make_fossil_species_map(
    sanger_tree_rooted, fossil_calibration_points,
    ppgi_taxonomy, equisetum_subgen, plastome_metadata_renamed),
  # Get pairs of tips that define fossil groups
  fossil_calibration_tips = get_fossil_calibration_tips(
    fossil_node_species_map, sanger_tree_rooted, fossil_calibration_points,
    manual_spanning_tips
  ),
  # Specify calibration point for root
  root_calibration = calibrate_root_node(
    sanger_tree_rooted, "land_plants", 475,
    "Anthoceros_angustus", "Polypodium_virginianum"
  ),
  # Format fossil calibration points for treePL
  fossil_calibrations_for_treepl = format_calibrations_for_treepl(
    fossil_calibration_tips, root_calibration
  ),
  # Dating with treePL ----
  # Run initial treepl search to identify smoothing parameter
  treepl_cv_results = run_treepl_cv(
    phy = sanger_tree_rooted,
    alignment = sanger_alignment,
    calibration_dates = fossil_calibrations_for_treepl,
    cvstart = "1000",
    cvstop = "0.000001",
    plsimaniter = "200000", # preliminary output suggested > 100000
    seed = 7167,
    thorough = TRUE,
    wd = path(int_dir, "treepl"),
    nthreads = 1,
    echo = TRUE
  ),
  # Run priming analysis to determine optimal states for other parameters
  treepl_priming_results = run_treepl_prime(
    phy = sanger_tree_rooted,
    alignment = sanger_alignment,
    calibration_dates = fossil_calibrations_for_treepl,
    cv_results = treepl_cv_results,
    plsimaniter = "200000", # preliminary output suggested > 100000
    seed = 7167,
    thorough = TRUE,
    wd = path(int_dir, "treepl"),
    nthreads = 1,
    echo = TRUE
  ),
  # Run treePL dating analysis
  plastid_tree_dated = run_treepl(
    phy = sanger_tree_rooted,
    alignment = sanger_alignment,
    calibration_dates = fossil_calibrations_for_treepl,
    cv_results = treepl_cv_results,
    priming_results = treepl_priming_results,
    plsimaniter = "200000", # preliminary output suggested > 100000
    seed = 7167,
    thorough = TRUE,
    wd = path(int_dir, "treepl"),
    nthreads = 7,
    echo = TRUE
  )
)
