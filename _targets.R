source("R/packages.R")
source("R/functions.R")

Sys.setenv(TAR_PROJECT = "main")

# Specify location of raw data
data_raw <- "_targets/user/data_raw"

# Specify location of intermediate results file
int_dir <- "_targets/user/intermediates"

# Specify location of final results file
results_dir <- "_targets/user/results"

# Set options:
# - Use targets workspaces for debugging
# - Track dependencies in some packages
# - Local parallelization with 20 workers
tar_option_set(
  workspace_on_error = TRUE,
  imports = c("taxastand", "pteridocat"),
  controller = crew_controller_local(workers = 20)
)

tar_plan(
  # Load data ----
  # Pteridocat taxonomic database
  pteridocat_db = pteridocat::pteridocat,
  # Modified PPGI taxonomy
  # with new genera and slightly different treatments following World Ferns list
  tar_file_read(
    ppgi_taxonomy,
    path(data_raw, "ppgi_taxonomy_mod.csv"),
    read_csv(!!.x)
  ),
  # Equisetum subgenus level taxonomy
  tar_file(equisteum_subgen_path, path(data_raw, "equisetum_subgenera.csv")),
  # List of coding genes to extract from plastomes
  # (based on genes of Wei et al 2017, then trimmed to non-duplicated genes)
  tar_file_read(
    target_plastome_genes,
    path(data_raw, "target_coding_genes.txt"),
    read_lines(!!.x)
  ),
  # Outgroup plastome accessions
  # (Some species names later get updated in plastome_metadata_renamed due to
  # pulling most recent taxonomy from NCBI)
  tar_file_read(
    plastome_outgroups,
    path(data_raw, "plastome_outgroups.csv"),
    read_csv(!!.x)
  ),
  # Manually curated list of GenBank accessions to exclude from analysis
  tar_file_read(
    accs_exclude,
    path(data_raw, "accs_exclude.csv"),
    read_csv(!!.x)
  ),
  # Reference alignments for assembling genes
  # generated by prep_ref_seqs_plan.R
  tar_file(
    ref_aln_files,
    list.files(
      path(data_raw, "ref_aln"),
      pattern = "\\.fasta",
      full.names = TRUE
    )
  ),
  fern_ref_seqs = load_ref_aln(ref_aln_files),
  # Path to local genbank database
  # build with ./R/setup_gb.R
  tar_file(restez_db, path(data_raw, "restez/sql_db")),
  tar_file_read(
    gb_release,
    path(data_raw, "restez/gb_release.txt"),
    as.numeric(readLines(!!.x))
  ),
  # Path to GenBank README
  tar_file(gb_readme_path, path(data_raw, "restez/README.genbank")),

  # Prep for assembling Sanger plastid regions ----
  # Define variables used in plan:
  # - Target plastid loci (coding genes and spacers)
  target_loci = c(
    "atpA", "atpB", "matK", "rbcL", "rps4",
    "trnL-trnF", "rps4-trnS"
  ),
  # - Target spacers only
  target_spacers = target_loci[str_detect(target_loci, "-")],
  # - Target plastome loci (full set of plastome genes plus spacers)
  target_plastome_loci = c(target_plastome_genes, target_spacers),
  # - Most recent date cutoff for sampling genes
  date_cutoff = get_gb_cutoff(gb_release, gb_readme_path),

  # Extract Sanger sequences ----

  # Load tibble of all accessions in local GenBank database.
  # (requires setting up database first; see R/setup_gb.R)
  accs_in_local_db = gb_get_all_ids(restez_db),
  # Fetch metadata
  tar_target(
    raw_meta_all,
    fetch_fern_metadata(
      target_loci,
      end_date = date_cutoff
    ),
    pattern = map(target_loci),
    deployment = "main"
  ),
  raw_meta = unique(raw_meta_all) %>%
    # Drop excluded sequences from metadata
    anti_join(accs_exclude, by = "accession") %>%
    # Limit to accession in local GenBank database
    inner_join(accs_in_local_db, by = "accession"),
  # Fetch sequences from local GenBank database
  tar_target(
    fern_sanger_seqs_raw,
    load_seqs_from_local_db(raw_meta, restez_db)
  ),
  tar_target(
    fern_sanger_extract_res,
    extract_from_ref_blast(
      query_seqtbl = fern_sanger_seqs_raw,
      ref_seqtbl = fern_ref_seqs,
      target = target_loci,
      blast_flavor = "dc-megablast",
      other_args = c("-m", "span", "--threads", "4")
    ),
    pattern = map(target_loci)
  ),
  raw_fasta_all = clean_extract_res(fern_sanger_extract_res, "dc-megablast"),
  # Drop excluded sequences
  raw_fasta = anti_join(raw_fasta_all, accs_exclude, by = "accession"),

  # Resolve taxonomic names for Sanger sequences ----
  # Specify varieties to exclude from collapsing
  # during taxonomic name resolution
  varieties_to_keep = define_varieties_to_keep(),
  # Extract species names from NCBI taxonomic database
  tar_target(
    ncbi_names_raw,
    extract_ncbi_names(
      taxdump_zip_file,
      taxid_keep = raw_meta,
      names_exclude = ncbi_db_names_to_exclude(),
      workers = 20
    ),
    deployment = "main"
  ),
  # Clean NCBI species names
  ncbi_names_full = clean_ncbi_names(ncbi_names_raw),
  # Exclude invalid names (hybrids, taxa not identified to species level)
  ncbi_names_query = exclude_invalid_ncbi_names(ncbi_names_full),
  # Parse reference names
  pc_ref_names = ts_parse_names(
    unique(pteridocat_db$scientificName),
    tbl_out = TRUE, quiet = TRUE
  ),
  # Resolve names, round 1: NCBI accepted scientific names
  ncbi_names_query_round_1 = select_ncbi_names_round_1(ncbi_names_query),
  # - match names to reference
  match_results_raw_round_1 = ts_match_names(
    query = ncbi_names_query_round_1$scientific_name,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE,
    match_canon = TRUE, collapse_infra = TRUE,
    collapse_infra_exclude = varieties_to_keep
  ),
  # - resolve synonyms
  match_results_resolved_round_1 = ts_resolve_names(
    match_results_raw_round_1, pteridocat_db
  ),
  # Resolve names, round 2: NCBI synonym scientific names
  ncbi_names_query_round_2 = select_ncbi_names_round_2(
    match_results_resolved_round_1, ncbi_names_query
  ),
  match_results_raw_round_2 = ts_match_names(
    query = ncbi_names_query_round_2$scientific_name,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE,
    match_canon = TRUE, collapse_infra = TRUE,
    collapse_infra_exclude = varieties_to_keep
  ),
  match_results_resolved_round_2 = ts_resolve_names(
    match_results_raw_round_2, pteridocat_db
  ),
  # Resolve names, round 3: NCBI species without author
  ncbi_names_query_round_3 = select_ncbi_names_round_3(
    match_results_resolved_round_1,
    match_results_resolved_round_2, ncbi_names_query
  ),
  match_results_raw_round_3 = ts_match_names(
    query = ncbi_names_query_round_3$species,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE,
    match_canon = TRUE, collapse_infra = TRUE,
    collapse_infra_exclude = varieties_to_keep
  ),
  match_results_resolved_round_3 = ts_resolve_names(
    match_results_raw_round_3, pteridocat_db
  ),
  # Combine name resolution results
  match_results_resolved_all =
    combined_match_results(
      ncbi_names_query = ncbi_names_query,
      match_results_resolved_round_1,
      match_results_resolved_round_2,
      match_results_resolved_round_3
    ),
  # CHECKPOINT: Inspect unmatched and fuzzily matched names
  # If any names need to be inspected, make_ncbi_accepted_names_map() will error
  pterido_names_to_inspect = inspect_ts_results(match_results_resolved_all),
  # Map NCBI names to accepted names
  ncbi_accepted_names_map = make_ncbi_accepted_names_map(
    match_results_resolved_all, pterido_names_to_inspect
  ),

  # Remove rogues from Sanger sequences ----
  # Combine sanger sequences and metadata, filter to resolved names
  # - set minimum lengths (bp) for filtering genes and spacers
  min_gene_len = 200,
  min_spacer_len = 20,
  sanger_seqs_combined_filtered = combine_and_filter_sanger(
    raw_meta, raw_fasta, ncbi_accepted_names_map,
    min_gene_len, min_spacer_len
  ),
  # - Make BLAST database including all fern sequences
  tar_file(
    sanger_blast_db,
    make_fern_blast_db(
      seqtbl = sanger_seqs_combined_filtered,
      blast_db_dir = path(int_dir, "blast_sanger"),
      out_name = "ferns_sanger"
    )
  ),
  # - Group query sequences for parallel computing
  tar_group_count(
    sanger_blast_query,
    dplyr::select(sanger_seqs_combined_filtered, seq, otu),
    count = 30
  ), # number of jobs to run in parallel
  # - Conduct all-by-all blast in parallel
  tar_target(
    all_by_all_blast,
    blast_seqtbl(
      seqtbl = sanger_blast_query,
      blastdb_files = sanger_blast_db
    ),
    pattern = map(sanger_blast_query)
  ),
  # - Identify rogues automatically (sequences matching wrong family)
  sanger_seqs_rogues_raw = detect_rogues(
    metadata_with_seqs = sanger_seqs_combined_filtered,
    blast_results = all_by_all_blast,
    ppgi_taxonomy
  ),
  # - Make sure family taxonomy is correct
  sanger_seqs_rogues_candidates = check_rogue_taxonomy(
    sanger_seqs_rogues_raw,
    raw_meta_all,
    ncbi_names_query,
    ppgi_taxonomy
  ),
  # - CHECKPOINT: verify that all candidate rogues have been manually inspected
  tar_file_read(
    sanger_seqs_rogues_inspected,
    path(data_raw, "rogues_inspected.csv"),
    read_csv(!!.x)
  ),
  sanger_seqs_rogues_verified = verify_rogues(
    sanger_seqs_rogues_candidates,
    sanger_seqs_rogues_inspected
  ),
  # - Remove rogues
  sanger_seqs_rogues_removed = anti_join(
    sanger_seqs_combined_filtered,
    sanger_seqs_rogues_verified,
    by = c("accession", "target")
  ),

  # Check for species monophyly in Sanger loci ----
  # - split sequence tibble up by target loci
  tar_target(
    mpcheck_sliced,
    filter(sanger_seqs_rogues_removed, target == target_loci),
    pattern = map(target_loci)
  ),
  # - align each locus
  tar_target(
    mpcheck_aligned,
    align_seqs_tbl(mpcheck_sliced),
    pattern = map(mpcheck_sliced)
  ),
  # - trim each locus
  # 1% missing cutoff for spacers, 5% otherwise nolint
  # name by accession since includes multiple sequences per species
  mpcheck_trimmed = trim_genes(mpcheck_aligned, name_col_in = "accession"),
  # - build tree for each locus
  tar_target(
    mpcheck_tree,
    build_tree_from_alignment_df(mpcheck_trimmed, program = "fasttree"),
    pattern = map(mpcheck_trimmed)
  ),
  # - check monophyly
  tar_target(
    mpcheck_monophy,
    check_monophy(mpcheck_sliced, mpcheck_tree, workers = 32),
    pattern = map(mpcheck_sliced, mpcheck_tree),
    deployment = "main"
  ),

  # Format custom inclusion list for Sanger sequences ----
  # Any species with accessions (sequences) in this data.frame
  # will be preferentially used over other sources.

  # Process Thelypteridaceae inclusion list from Patel el al. (2019)
  patel_inclusion_list = create_patel_inclusion_list(
    path_to_patel_data = contentid::resolve("hash://sha256/233607dc3945dc0f764c44d1171f8bd8bdfe50c4028c9c44e82965e5a5f11fdc"), # nolint
    pteridocat = pteridocat_db
  ),
  # Load manual inclusion list
  tar_file_read(
    manual_inclusion_list,
    "_targets/user/data_raw/accs_manual.csv",
    read_csv(file = !!.x)
  ),
  # Combine Patel et al and manual lists
  inclusion_list = combine_inclusion_lists(
    patel_inclusion_list,
    manual_inclusion_list
  ),

  # Select final Sanger sequences ----
  # First parse specimen voucher data
  sanger_seqs_with_voucher_data = parse_voucher(sanger_seqs_rogues_removed),
  # Join sequences across species, then select one set of sequences per species
  # Criteria for joining sequences across species:
  # - species is monophyletic, or
  # - all sequences for that species are from the same voucher, or
  # - all sequences for that species are from same publication
  # Criteria for selecting final set of sequences for each species (in order):
  # - 1. species with manually specified sequences
  # - 2. species with longest combined rbcL + other genes
  # - 3. species with longest rbcL (lacking other genes)
  # - 4. species with the greatest combined length of other genes
  sanger_accessions_selection = select_genbank_genes(
    sanger_seqs_with_voucher_data, mpcheck_monophy,
    manually_selected_seqs = inclusion_list
  ),

  # Extract core set of plastid genes from plastomes ----
  # Download plastome metadata (accessions and species)
  plastome_metadata_raw_all = download_plastome_metadata(
    end_date = date_cutoff,
    outgroups = plastome_outgroups
  ),
  # Drop sequences to exclude
  plastome_metadata_raw = anti_join(
    plastome_metadata_raw_all,
    accs_exclude,
    by = "accession"
  ),
  # Extract species names in plastome data from NCBI taxonomy
  # Be sure to obtain hash of most recent taxdump file from
  # https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump_archive/
  # before running
  tar_file(
    taxdump_zip_file,
    # new_taxdump_2023-07-01.zip
    contentid::resolve(
      "hash://sha256/442f3eaa00666cffc5f74d9855d5ac2d5b8b55cf87bc7542e87322830bbf2038" # nolint
    )
  ),
  plastome_ncbi_names_raw = extract_ncbi_names(
    taxdump_zip_file,
    taxid_keep = plastome_metadata_raw,
    names_exclude = plastome_ncbi_db_names_to_exclude(),
    workers = 2
  ),
  # Resolve species names in plastome metadata
  # (drops accession if name could not be resolved and fix some names)
  plastome_metadata_renamed = resolve_pterido_plastome_names(
    plastome_ncbi_names_raw, plastome_metadata_raw, plastome_outgroups,
    ref_names_parsed = pc_ref_names, ref_names_data = pteridocat_db
  ),
  # Extract plastome sequences
  # FASTA files for each accession in seqtbl format
  target_plastome_accessions = unique(plastome_metadata_renamed$accession),
  tar_target(
    plastome_fasta,
    gb_dnabin_get(
      id = target_plastome_accessions,
      restez_path = restez_db
    )
  ),
  # Extract target genes and spacers with superCRUNCH
  tar_target(
    fern_plastome_loci_extract_res,
    extract_from_ref_blast(
      query_seqtbl = mutate(plastome_fasta, gene = target_plastome_loci),
      ref_seqtbl = fern_ref_seqs,
      target = target_plastome_loci,
      blast_flavor = "dc-megablast",
      other_args = c("-m", "span", "--threads", "4")
    ),
    pattern = map(target_plastome_loci)
  ),
  plastome_genes_raw = clean_extract_res(
    fern_plastome_loci_extract_res, "dc-megablast"
  ),
  # Combine plastome metadata and sequences, filter to best accession per taxon
  plastome_seqs_combined_filtered = select_plastome_seqs(
    plastome_genes_raw,
    plastome_metadata_renamed
  ),

  # Align spacers ----
  # Assign taxonomic clusters (by family) for aligning spacer regions
  tar_target(
    plastid_spacers_unaligned,
    assign_tax_clusters(
      sanger_accessions_selection,
      sanger_seqs_combined_filtered,
      plastome_seqs_combined_filtered,
      ppgi_taxonomy, plastome_metadata_renamed,
      target_spacers
    ),
    pattern = map(target_spacers),
  ), # - configure groups for aligning in parallel
  tar_target(
    plastid_spacers_unaligned_grouped,
    plastid_spacers_unaligned %>%
      filter(cluster != "none") %>%
      group_by(target, cluster) %>%
      tar_group(),
    iteration = "group"
  ),
  # Align each cluster
  tar_target(
    plastid_spacers_aligned_clusters,
    align_seqs_tbl(plastid_spacers_unaligned_grouped),
    pattern = map(plastid_spacers_unaligned_grouped),
    iteration = "vector"
  ),
  # Trim each cluster, rename each sequence by taxon
  # (Use a very light threshold, to keep most gaps)
  plastid_spacers_aligned_trimmed_clusters = trim_spacers_by_cluster(
    plastid_spacers_aligned_clusters
  ),
  # Also make overall alignment with one representative
  # per cluster to identify sequences needing reverse-complement
  tar_target(
    plastid_spacers_rep_align,
    align_rep_spacers(
      plastid_spacers_aligned_trimmed =
        plastid_spacers_aligned_trimmed_clusters, # clusters
      plastid_spacers_unaligned, # singletons
      target_select = target_spacers,
      exclude_terms = "Anemiaceae"
    ), # exclude Anemiaceae, too variable to align
    pattern = map(target_spacers)
  ),
  # Reverse-complement spacers
  plastid_spacers_aligned_trimmed_reversed_clusters = reverse_spacers(
    plastid_spacers_aligned_trimmed_clusters, plastid_spacers_rep_align
  ),
  # Merge subalignments
  tar_target(
    plastid_spacers_aligned_trimmed,
    merge_spacer_alignments(
      plastid_spacers_aligned_trimmed_reversed_clusters,
      n_threads = 10,
      target_select = target_spacers
    ),
    pattern = map(target_spacers)
  ),

  # Align genes ----
  # Combine Sanger and plastome genes into single dataframe, group by gene
  plastid_genes_unaligned_full = combine_sanger_plastome(
    # Exclude spacer regions (spacer regions have hyphen in name)
    sanger_accessions_selection = sanger_accessions_selection %>%
      select(-contains("-")),
    sanger_seqs_combined_filtered = sanger_seqs_combined_filtered %>%
      filter(str_detect(target, "-", negate = TRUE)),
    plastome_seqs_combined_filtered = plastome_seqs_combined_filtered %>%
      filter(str_detect(target, "-", negate = TRUE))
  ),
  # Filter out any species not meeting custom requirements
  # (minimum seq length and num loci for certain species)
  filter_tibble = load_filter_tibble(),
  species_to_remove_custom = make_custom_species_filter(
    plastid_genes_unaligned_full,
    filter_tibble
  ),
  plastid_genes_unaligned = anti_join(
    plastid_genes_unaligned_full,
    species_to_remove_custom,
    by = "species"
  ),
  # Align sequences by gene
  tar_group_by(
    plastid_genes_unaligned_grouped,
    plastid_genes_unaligned,
    target,
  ),
  tar_target(
    plastid_genes_aligned,
    align_seqs_tbl(plastid_genes_unaligned_grouped),
    pattern = map(plastid_genes_unaligned_grouped)
  ),
  # Trim alignments, rename each sequence by taxon
  plastid_genes_aligned_trimmed = trim_genes(plastid_genes_aligned),

  # Concatenate alignments ----
  # - tbl format
  sanger_alignment_tbl = concatenate_plastid_sanger(
    plastid_genes_aligned_trimmed,
    plastid_spacers_aligned_trimmed,
    target_loci,
    type_select = "sanger"
  ),
  plastome_alignment_tbl = concatenate_plastid_sanger(
    plastid_genes_aligned_trimmed,
    plastid_spacers_aligned_trimmed,
    target_loci,
    type_select = "plastome"
  ),
  # - ape format
  sanger_alignment = concatenate_to_ape(sanger_alignment_tbl),
  plastome_alignment = concatenate_to_ape(plastome_alignment_tbl),

  # Phylogenetic analysis ----
  # Backbone consensus tree
  tar_target(
    plastome_tree,
    iqtree(
      plastome_alignment,
      m = "MFP", # test model followed by ML analysis
      bb = 1000,
      nt = 12, # run 12 cores in parallel
      seed = 20220123,
      redo = TRUE, echo = TRUE, wd = path(int_dir, "iqtree/plastome"),
      other_args = c(
        "-mset", "GTR", # only test GTR models
        "-mrate", "E,I,G,I+G", # don't test free-rate models
        "-t", "PARS"
      ),
      tree_path = path(
        int_dir, "iqtree/plastome/plastome_alignment.phy.contree"
      )
    ),
    deployment = "main"
  ),
  # write out as plastome tree to use as constraint
  tar_file(
    constraint_tree_file,
    write_tree_tar(
      plastome_tree,
      path(int_dir, "iqtree/constraint.tre")
    )
  ),
  # Initial Sanger tree (fast mode)
  tar_target(
    sanger_tree_fast,
    iqtree(
      sanger_alignment,
      m = "GTR+I+G", nt = 6, seed = 20220129,
      redo = TRUE, echo = TRUE, wd = path(int_dir, "iqtree/sanger_fast"),
      other_args = c(
        "-fast",
        "-t", "PARS",
        "-alrt", "1000",
        "-g", path_abs(constraint_tree_file)
      )
    )
  ),
  # CHECKPOINT: verify non-monophyletic taxa in fast tree
  # All non-monophyletic taxa should be in notes, except for taxa_exclude
  # If error issued, update non_mono_notes or taxa_exclude after inspection
  tar_file_read(
    non_mono_notes,
    path(data_raw, "non_mono_notes.csv"),
    read_csv(!!.x)
  ),
  non_mono_check = verify_non_mono_taxa(
    fast_monophy_by_clade,
    non_mono_notes,
    taxa_exclude = tibble(
      taxon = c(
        # Commented list of false positives from past runs
        "Abrodictyum",
        # "Adiantopsis",
        # "Arachniodes",
        # "Calochlaena",
        # "Didymoglossum",
        "Dryopteridoideae",
        # "Dryopteris",
        # "Goniopteris",
        # "Lytoneuron",
        # "Notogrammitis",
        # "Ormopteris",
        "Phanerophlebia",
        "Polybotryoideae",
        "Polystichum",
        # "Pseudocyclosorus",
        # "Saccoloma",
        "Sceptridium"
        # "Strophocaulon",
        # "Syngramma"
      )
    )
  ),
  # Sanger ML tree: best of 10 replicates
  # - set 10 different seeds
  iqtree_sanger_seeds = 220307 + 1:10,
  iqtree_sanger_dirs = path(int_dir, paste0("iqtree/sanger_", 1:10)),
  # - run 10 independent reps
  tar_target(
    sanger_ml_tree_rep,
    iqtree(
      sanger_alignment,
      m = "MFP", # run modelfinder and use best model
      other_args = c(
        "-mset", "GTR", # only test GTR family of models
        "-mrate", "E,I,G,I+G",
        "-t", "PARS",
        "-g", path_abs(constraint_tree_file)
      ),
      bb = 1000,
      nt = 6, # run 6 cores in parallel for each replicate
      seed = iqtree_sanger_seeds,
      # redo settings:
      # - FALSE to re-start incomplete iqtree run on same data
      # - TRUE when starting pipeline from new data
      redo = TRUE,
      wd = iqtree_sanger_dirs,
      tree_path = c(
        ml_tree = path(iqtree_sanger_dirs, "sanger_alignment.phy.treefile"),
        con_tree = path(iqtree_sanger_dirs, "sanger_alignment.phy.contree")
      ),
      depends = non_mono_check
    ),
    pattern = map(iqtree_sanger_seeds, iqtree_sanger_dirs),
    iteration = "list"
  ),
  # Read in log files for each replicate
  tar_target(
    sanger_ml_log_rep,
    read_lines_tar(
      path(iqtree_sanger_dirs, "sanger_alignment.phy.log"),
      depends = sanger_ml_tree_rep
    ),
    pattern = map(iqtree_sanger_dirs, sanger_ml_tree_rep)
  ),
  # Read in log file from Sanger ML tree analysis
  sanger_ml_log = get_best_tree(sanger_ml_log_rep, "log"),
  # Get best ML tree from ML tree replicates
  sanger_ml_tree = get_best_tree(sanger_ml_log_rep, "ml"),
  # Get best consensus tree from ML tree replicates
  sanger_con_tree = get_best_tree(sanger_ml_log_rep, "con"),
  # Check monophyly ----
  # Root tree on Zygnema
  # - rapid ML tree
  sanger_fast_tree_rooted = root_fern_tree(sanger_tree_fast),
  # - ML tree
  sanger_ml_tree_rooted = root_fern_tree(sanger_ml_tree),
  # - consensus tree
  sanger_con_tree_rooted = root_fern_tree(sanger_con_tree),
  # Drop Zygnema for dating
  og_to_drop = "Zygnema_circumcarinatum",
  sanger_ml_tree_rooted_pruned = ape::drop.tip(
    sanger_ml_tree_rooted, og_to_drop
  ),
  sanger_con_tree_rooted_pruned = ape::drop.tip(
    sanger_con_tree_rooted, og_to_drop
  ),
  # Load Equisetum data (only group with subgenera in fossils)
  equisetum_subgen = load_equisetum_subgen(
    equisteum_subgen_path,
    sanger_fast_tree_rooted
  ), # fast or final OK
  # Define groups for checking monophyly
  taxa_levels_check = c(
    "order", "suborder", "family",
    "subfamily", "genus", "subgenus"
  ),
  # Make tibble mapping species to putatively monophyletic groups
  sanger_sampling = make_sanger_sampling_tbl(
    plastome_metadata_renamed,
    sanger_tree = sanger_fast_tree_rooted, # fast or final OK
    ppgi_taxonomy = ppgi_taxonomy
  ) %>% left_join(equisetum_subgen, by = "species"), # Add Equisetum subgenera
  # Check monophyly
  # - Fast tree (runs before final tree)
  fast_mono_test = assess_monophy(
    taxon_sampling = sanger_sampling,
    tree = sanger_fast_tree_rooted,
    tax_levels = taxa_levels_check
  ),
  fast_monophy_by_clade = map_df(
    seq_along(taxa_levels_check),
    ~ get_result_monophy(fast_mono_test, .)
  ),
  # - ML tree
  ml_mono_test = assess_monophy(
    taxon_sampling = sanger_sampling,
    tree = sanger_ml_tree_rooted,
    tax_levels = taxa_levels_check
  ),
  ml_monophy_by_clade = map_df(
    seq_along(taxa_levels_check),
    ~ get_result_monophy(ml_mono_test, .)
  ),
  # - consensus tree
  con_mono_test = assess_monophy(
    taxon_sampling = sanger_sampling,
    tree = sanger_con_tree_rooted,
    tax_levels = taxa_levels_check
  ),
  con_monophy_by_clade = map_df(
    seq_along(taxa_levels_check),
    ~ get_result_monophy(con_mono_test, .)
  ),
  # Prepare fossil calibrations ----
  # Load fossil calibration points
  # Fossil calibration points (ferncal v1.0.1)
  ferncal_version = "1.0.1",
  fossil_ferns_raw = read_csv(
    resolve_fern_fossils(ferncal_version)
  ),
  # Drop MD formatting (asterisks) from data
  fossil_ferns_all = mutate(
    fossil_ferns_raw,
    across(where(is.character), ~ str_remove_all(., "\\*"))
  ),
  # Filter fossil calibration points
  fossil_calibration_points = filter_fossil_calibration_points(
    fossil_ferns_all
  ),
  # Define some tips for spanning non-monophyletic groups
  manual_spanning_tips = define_manual_spanning_tips("this_study"),
  # Specify calibration point for root
  ml_root_calibration = calibrate_root_node(
    sanger_ml_tree_rooted_pruned, "land_plants", 475,
    "Marchantia_polymorpha", "Polypodium_virginianum"
  ),
  con_root_calibration = calibrate_root_node(
    sanger_con_tree_rooted_pruned, "land_plants", 475,
    "Marchantia_polymorpha", "Polypodium_virginianum"
  ),
  # Map species in the tree to their fossil groups
  # - ML tree
  ml_fossil_node_species_map = make_fossil_species_map(
    sanger_ml_tree_rooted_pruned, fossil_calibration_points,
    ppgi_taxonomy, equisetum_subgen,
    # don't include pruned outgroup in metadata
    filter(plastome_metadata_renamed, species != og_to_drop)
  ),
  # - consensus tree
  con_fossil_node_species_map = make_fossil_species_map(
    sanger_con_tree_rooted_pruned, fossil_calibration_points,
    ppgi_taxonomy, equisetum_subgen,
    filter(plastome_metadata_renamed, species != og_to_drop)
  ),
  # Get pairs of tips that define fossil groups.
  # Also drops redundant calibration points.
  # - ML tree
  ml_fossil_calibration_tips = get_fossil_calibration_tips(
    fossil_node_species_map = ml_fossil_node_species_map,
    sanger_tree_rooted = sanger_ml_tree_rooted_pruned,
    fossil_calibration_points, manual_spanning_tips
  ),
  # - consensus tree
  con_fossil_calibration_tips = get_fossil_calibration_tips(
    fossil_node_species_map = con_fossil_node_species_map,
    sanger_tree_rooted = sanger_con_tree_rooted_pruned,
    fossil_calibration_points, manual_spanning_tips
  ),
  # Format fossil calibration points for treePL
  # - ML tree
  ml_fossil_calibrations_for_treepl = format_calibrations_for_treepl(
    ml_fossil_calibration_tips, ml_root_calibration
  ),
  # - consensus tree
  con_fossil_calibrations_for_treepl = format_calibrations_for_treepl(
    con_fossil_calibration_tips, con_root_calibration
  ),
  # Format Testo and Sundue 2016 calibration points for comparison
  # (consensus tree only)
  ts_fossil_calibration_points = parse_ts_calibrations(
    testo_sundue_2016_si_path = contentid::resolve(
      "hash://sha256/c629f4617e7e2329a10cb1b207b82a6720653a67eafcaaa97cc6ee891ae7fdf7" # nolint
    )
  ),
  ts_fossil_node_species_map = make_ts_fossil_species_map(
    sanger_con_tree_rooted_pruned,
    ts_fossil_calibration_points,
    ppgi_taxonomy,
    # don't include pruned outgroup in metadata
    filter(plastome_metadata_renamed, species != og_to_drop)
  ),
  ts_manual_spanning_tips = define_manual_spanning_tips("ts2016"),
  ts_fossil_calibration_tips = get_fossil_calibration_tips(
    ts_fossil_node_species_map, sanger_con_tree_rooted_pruned,
    ts_fossil_calibration_points, ts_manual_spanning_tips
  ),
  ts_fossil_calibrations_for_treepl = format_calibrations_for_treepl(
    ts_fossil_calibration_tips, con_root_calibration
  ),
  # Dating with treePL ----
  # - ML tree, FernCal calibrations
  sanger_ml_tree_dated = run_treepl_combined(
    phy = sanger_ml_tree_rooted_pruned,
    alignment = sanger_alignment,
    calibration_dates = ml_fossil_calibrations_for_treepl,
    cvstart = 1e-6,
    cvstop = 1e-12,
    cvsimaniter = 5000,
    plsimaniter = 200000, # preliminary output suggested > 100000
    nthreads = 5,
    seed = 2808,
    wd = path(int_dir, "treepl/ml"),
    thorough = TRUE
  ),
  # - Consensus tree, FernCal calibrations
  sanger_con_tree_dated = run_treepl_combined(
    phy = sanger_con_tree_rooted_pruned,
    alignment = sanger_alignment,
    calibration_dates = con_fossil_calibrations_for_treepl,
    cvstart = 1e-6,
    cvstop = 1e-12,
    cvsimaniter = 5000,
    plsimaniter = 200000,
    nthreads = 5,
    seed = 3732,
    wd = path(int_dir, "treepl/con"),
    thorough = TRUE
  ),
  # - Consensus tree, Testo and Sundue calibrations
  # use CV results from consensus tree
  sanger_con_cv = read_lines_tar(
    path(int_dir, "treepl/con/treepl_cv_out.txt"),
    depends = sanger_con_tree_dated
  ),
  ts_sanger_tree_prime = run_treepl_prime(
    phy = sanger_con_tree_rooted_pruned,
    alignment = sanger_alignment,
    calibration_dates = ts_fossil_calibrations_for_treepl,
    cv_results = sanger_con_cv,
    cvsimaniter = 5000,
    plsimaniter = 200000,
    nthreads = 5,
    seed = 7970,
    wd = path(int_dir, "treepl/ts"),
    thorough = TRUE
  ),
  ts_sanger_tree_dated = run_treepl(
    phy = sanger_con_tree_rooted_pruned,
    alignment = sanger_alignment,
    calibration_dates = ts_fossil_calibrations_for_treepl,
    cv_results = sanger_con_cv,
    priming_results = ts_sanger_tree_prime,
    cvsimaniter = 5000,
    plsimaniter = 200000,
    nthreads = 5,
    seed = 7970,
    wd = path(int_dir, "treepl/ts"),
    thorough = TRUE
  ),
  # Format data for ftolr ----
  acc_table_long = make_long_acc_table(
    raw_meta, sanger_seqs_combined_filtered,
    plastome_seqs_combined_filtered,
    ncbi_names_query, sanger_accessions_selection,
    plastome_metadata_renamed,
    plastome_metadata_raw,
    plastome_ncbi_names_raw
  ),
  acc_table_wide = make_wide_acc_table(
    acc_table_long, sanger_accessions_selection
  ),
  plastome_parts_table = make_parts_table(
    plastome_alignment_tbl, plastome_alignment
  ),
  sanger_parts_table = make_parts_table(
    sanger_alignment_tbl, sanger_alignment
  ),
  plastome_tree_rooted = root_fern_tree(plastome_tree),
  # Write out data for ftolr ----
  # - Accessions
  tar_file(
    acc_table_long_ftolr,
    write_csv_tar(
      acc_table_long,
      "ftol_data/ftol_acc_table_long.csv"
    )
  ),
  tar_file(
    acc_table_wide_ftolr,
    write_csv_tar(
      acc_table_wide,
      "ftol_data/ftol_acc_table_wide.csv"
    )
  ),
  # - Taxonomy
  tar_file(
    sanger_sampling_ftolr,
    write_csv_tar(
      sanger_sampling,
      "ftol_data/ftol_sanger_sampling.csv"
    )
  ),
  tar_file(
    match_results_ftolr,
    write_csv_tar(
      match_results_resolved_all,
      "ftol_data/ftol_match_results.csv"
    )
  ),
  # - Trees (all trees should be rooted)
  # -- plastome consensus
  tar_file(
    plastome_tree_ftolr,
    write_tree_tar(
      plastome_tree_rooted,
      "ftol_data/ftol_plastome_con.tre"
    )
  ),
  # -- sanger ML
  tar_file(
    sanger_ml_tree_ftolr,
    write_tree_tar(
      sanger_ml_tree_rooted,
      "ftol_data/ftol_sanger_ml.tre"
    )
  ),
  # -- sanger ML dated
  tar_file(
    sanger_ml_tree_dated_ftolr,
    write_tree_tar(
      sanger_ml_tree_dated,
      "ftol_data/ftol_sanger_ml_dated.tre"
    )
  ),
  # -- sanger consensus
  tar_file(
    sanger_con_tree_ftolr,
    write_tree_tar(
      sanger_con_tree_rooted,
      "ftol_data/ftol_sanger_con.tre"
    )
  ),
  # -- sanger consensus dated
  tar_file(
    sanger_con_tree_dated_ftolr,
    write_tree_tar(
      sanger_con_tree_dated,
      "ftol_data/ftol_sanger_con_dated.tre"
    )
  ),
  # - Alignments
  tar_file(
    sanger_alignment_ftolr,
    write_fasta_gz_tar(
      sanger_alignment,
      "ftol_data/ftol_sanger_alignment.fasta.gz"
    )
  ),
  tar_file(
    plastome_alignment_ftolr,
    write_fasta_gz_tar(
      plastome_alignment,
      "ftol_data/ftol_plastome_alignment.fasta.gz"
    )
  ),
  # - Alignment parts
  tar_file(
    plastome_parts_table_ftolr,
    write_csv_tar(
      plastome_parts_table,
      "ftol_data/ftol_plastome_parts.csv"
    )
  ),
  tar_file(
    sanger_parts_table_ftolr,
    write_csv_tar(
      sanger_parts_table,
      "ftol_data/ftol_sanger_parts.csv"
    )
  ),
  # - Calibration points
  tar_file(
    con_fossil_calibration_tips_ftolr,
    write_csv_tar(
      con_fossil_calibration_tips,
      "ftol_data/ftol_sanger_con_fossils.csv"
    )
  ),
  tar_file(
    ml_fossil_calibration_tips_ftolr,
    write_csv_tar(
      ml_fossil_calibration_tips,
      "ftol_data/ftol_sanger_ml_fossils.csv"
    )
  ),
  # Compress data for FigShare
  # - ref alignments
  tar_file(
    ref_aln_archive,
    archive_dir(
      archive = path(data_raw, "ref_aln.tar.gz"),
      dir = path(data_raw, "ref_aln"),
      format = "tar",
      filter = "gzip",
      depends = ref_aln_files
    )
  ),
  # - restez db (already compressed by setup_gb.R)
  tar_file(
    restez_sql_db_archive,
    path(data_raw, "restez_sql_db.tar.gz")
  ),
  # Render READMEs
  # - input data README for figshare
  tar_render(
    input_data_readme,
    "reports/input_data_readme/input_data_readme.Rmd",
    output_dir = results_dir,
    output_format = "readmedown::plain_document",
    knit_root_dir = "reports/input_data_readme"
  ),
  # - input data README for github
  tar_render(
    input_data_readme_gh,
    "reports/input_data_readme/input_data_readme_gh.Rmd",
    output_dir = data_raw,
    output_file = "README",
    output_format = "readmedown::plain_document",
    knit_root_dir = "reports/input_data_readme"
  ),
  # - output data README for ftolr package
  tar_render(
    ftol_data_readme,
    "reports/ftol_data_readme/ftol_data_readme.Rmd",
    output_dir = "ftol_data",
    output_file = "ftol_data_README.txt",
    output_format = "readmedown::plain_document",
    knit_root_dir = "reports/ftol_data_readme"
  ),
  # Document software versions
  # - R package versions
  tar_file_read(
    renv_pkg_versions,
    "renv.lock",
    get_renv_pkg_versions(!!.x)
  ),
  # - Other software versions
  tar_file_read(
    sw_versions,
    "Dockerfile",
    get_sw_versions(!!.x)
  ),
  # - Current R version
  ftol_r_ver = paste(R.Version()[c("major", "minor")], collapse = "."),
  # - Fetch docker image tag
  #   This only works if plan is made with run.sh
  #   otherwise, will be empty string ("")
  tar_target(
    image_tag,
    get_docker_tag(),
    cue = tar_cue(mode = "always")
  )
)
