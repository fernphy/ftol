library(targets)
library(tarchetypes)
source("R/packages.R")
source("R/functions.R")

# Specify path to folder with raw data
data_raw <- "/data_raw"

# Set parallel back-end
plan(callr)

# Set options:
# - Use targets workspaces for debugging
# - Track dependencies in some packages
tar_option_set(
  workspace_on_error = TRUE #,
  # imports = c("pteridocat") # FIXME: uncomment when {pteridocat} is live
  )

tar_plan(
  # Load data ----
  # FIXME: temporary work-around for loading pteridocat data
  # until {pteridocat} package is live
  tar_file(pteridocat_file, "working/pteridocat.RDS"),
  pteridocat = readRDS(pteridocat_file),
  # - Modified PPGI taxonomy
  # with new genera and slightly different treatments following World Ferns list
  tar_file(
    ppgi_taxonomy_path,
    path(data_raw, "ppgi_taxonomy_mod.csv")),
  ppgi_taxonomy = read_csv(ppgi_taxonomy_path),
  # List of coding genes to extract from plastomes
  # (based on genes of Wei et al 2017, then trimmed to non-duplicated genes)
  tar_file(
    target_plastome_genes_path,
    path(data_raw, "target_coding_genes.txt")),
  target_plastome_genes = read_lines(target_plastome_genes_path),
  # Outgroup plastome accessions
  tar_file(
    plastome_outgroups_path,
    path(data_raw, "plastome_outgroups.csv")),
  plastome_outgroups = read_csv(plastome_outgroups_path),
  # Calibration dates after Testo and Sundue 2016
  tar_file(
    plastome_calibration_dates_path,
    path(data_raw, "testo_sundue_2016_calibrations.csv")),
  plastid_calibration_dates = load_calibration_dates(
    plastome_calibration_dates_path),
  # Manually selected synonyms for resolving names of plastid genes
  tar_file(
    sanger_names_with_mult_syns_select_path,
    path(data_raw, "genbank_names_with_mult_syns_select.csv")),
  sanger_names_with_mult_syns_select = read_csv(
    sanger_names_with_mult_syns_select_path),
  # Manually curated list of raw fasta accessions to exclude from analysis
  tar_file(
    raw_fasta_exclude_list_path,
    path(data_raw, "raw_fasta_exclude_list.csv")),
  raw_fasta_exclude_list = read_csv(raw_fasta_exclude_list_path),
  # Reference alignments for assembling genes
  # generated by prep_ref_seqs_plan.R
  tar_file(
    ref_aln_files,
    list.files(data_raw, "ref_aln_.*\\.fasta", full.names = TRUE)
  ),
  fern_ref_seqs = load_ref_aln(ref_aln_files),

  # Prep for assembling Sanger plastid regions ----
  # Define variables used in plan:
  # - Target plastic loci (coding genes and spacers)
  target_loci = c(
    "atpA", "atpB", "matK", "rbcL", "rps4",
    "trnL-trnF", "rps4-trnS"),
  # - Most recent date cutoff for sampling genes
  date_cutoff = "2021/10/26",

  # Download and extract Sanger sequences ----
  # Download raw fasta files
  tar_target(
    fern_sanger_seqs_raw,
    fetch_fern_sanger_seqs(
      target_loci, end_date = date_cutoff, accs_exclude_list = NULL),
    pattern = map(target_loci),
    # don't run in parallel, or will get HTTP status 429 errors
    deployment = "main"
  ),
  # Extract target regions with superCRUNCH
  tar_target(
    fern_sanger_extract_res,
    extract_from_ref_blast(
      query_seqtbl = fern_sanger_seqs_raw,
      ref = fern_ref_seqs,
      target = target_loci,
      blast_flavor = "dc-megablast",
      other_args = c("-m", "span", "--threads", "4")
    ),
    pattern = map(target_loci)
  ),
  raw_fasta = clean_extract_res(fern_sanger_extract_res, "dc-megablast"),
  # Fetch metadata
  tar_target(
    raw_meta_all,
    fetch_fern_metadata(target_loci, end_date = date_cutoff),
    pattern = map(target_loci),
    deployment = "main"
  ),
  raw_meta = unique(raw_meta_all),

  # Resolve taxonomic names for Sanger sequences ----
  # Download species names from NCBI
  ncbi_names_raw = raw_meta %>% pull(taxid) %>% unique %>% fetch_taxonomy,
  # Clean NCBI species names
  ncbi_names_full = clean_ncbi_names(ncbi_names_raw),
  # Exclude invalid names (hybrids, taxa not identified to species level)
  ncbi_names_query = exclude_invalid_ncbi_names(ncbi_names_full),
  # Parse reference names
  pc_ref_names = ts_parse_names(unique(pteridocat$scientificName)),
  # Resolve names, round 1: NCBI accepted scientific names
  ncbi_names_query_round_1 = select_ncbi_names_round_1(ncbi_names_query),
  # - match names to reference
  match_results_raw_round_1 = ts_match_names(
    query = ncbi_names_query_round_1$scientific_name,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE, match_canon = TRUE),
  # - resolve synonyms
  match_results_resolved_round_1 = ts_resolve_names(
    match_results_raw_round_1, pteridocat),
  # Resolve names, round 2: NCBI synonym scientific names
  ncbi_names_query_round_2 = select_ncbi_names_round_2(
    match_results_resolved_round_1, ncbi_names_query),
  match_results_raw_round_2 = ts_match_names(
    query = ncbi_names_query_round_2$scientific_name,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE, match_canon = TRUE),
  match_results_resolved_round_2 = ts_resolve_names(
    match_results_raw_round_2, pteridocat),
  # Resolve names, round 3: NCBI species without author
  ncbi_names_query_round_3 = select_ncbi_names_round_3(
    match_results_resolved_round_1,
    match_results_resolved_round_2, ncbi_names_query),
  match_results_raw_round_3 = ts_match_names(
    query = ncbi_names_query_round_3$species,
    reference = pc_ref_names,
    max_dist = 5, match_no_auth = TRUE, match_canon = TRUE),
  match_results_resolved_round_3 = ts_resolve_names(
    match_results_raw_round_3, pteridocat),
  # Combine name resolution results
  match_results_resolved_all =
    combined_match_results(
      ncbi_names_query = ncbi_names_query,
      match_results_resolved_round_1,
      match_results_resolved_round_2,
      match_results_resolved_round_3),
  # Map NCBI names to accepted names
  ncbi_accepted_names_map = make_ncbi_accepted_names_map(
    match_results_resolved_all),

  # Remove rogues from Sanger sequences ----
  # Combine sanger sequences and metadata, filter to resolved names
  # - set minimum lengths (bp) for filtering genes and spacers
  min_gene_len = 200,
  min_spacer_len = 20,
  sanger_seqs_combined_filtered = combine_and_filter_sanger(
    raw_meta, raw_fasta, ncbi_accepted_names_map,
    ppgi_taxonomy, min_gene_len, min_spacer_len),
  # Make BLAST database including all fern sequences
  tar_file(
    sanger_blast_db,
    make_fern_blast_db(
      seqtbl = sanger_seqs_combined_filtered,
      blast_db_dir = "intermediates/blast_sanger",
      out_name = "ferns_sanger")
  ),
  # Group query sequences for parallel computing
  tar_group_count(
    sanger_blast_query,
    dplyr::select(sanger_seqs_combined_filtered, seq, otu),
    count = 30), # number of jobs to run in parallel
  # Conduct all-by-all blast in parallel
  tar_target(
    all_by_all_blast,
    blast_seqtbl(
      seqtbl = sanger_blast_query,
      blastdb_files = sanger_blast_db
    ),
    pattern = map(sanger_blast_query)
  ),
  # Identify rogues (sequences matching wrong family)
  # FIXME: many of these are due to bad taxonomy.
  # inspect results and modify WF taxonomy as needed
  sanger_seqs_rogues = detect_rogues(
    metadata_with_seqs = sanger_seqs_combined_filtered,
    blast_results = all_by_all_blast,
    ppgi = ppgi_taxonomy),
  sanger_seqs_rogues_removed = anti_join(
    sanger_seqs_combined_filtered,
    sanger_seqs_rogues,
    by = c("accession", "target")
  ),

  # Check for species monophyly in Sanger loci ----
  # - split sequence tibble up by target loci
  tar_target(
    mpcheck_sliced,
    filter(sanger_seqs_rogues_removed, target == target_loci),
    pattern = map(target_loci)
  ),
  # - align each locus
  tar_target(
    mpcheck_aligned,
    align_seqs_tbl(mpcheck_sliced),
    pattern = map(mpcheck_sliced)
  ),
  # - trim each locus
  # 1% missing cutoff for spacers, 5% otherwise nolint
  # name by accession since includes multiple sequences per species
  mpcheck_trimmed = trim_genes(mpcheck_aligned, name_col_in = "accession"),
  # - build tree for each locus
  tar_target(
    mpcheck_tree,
    build_tree_from_alignment_df(mpcheck_trimmed, program = "fasttree"),
    pattern = map(mpcheck_trimmed)
  ),
  # - check monophyly
  tar_target(
    mpcheck_monophy,
    check_monophy(mpcheck_sliced, mpcheck_tree, workers = 32),
    pattern = map(mpcheck_sliced, mpcheck_tree),
    deployment = "main"
  ),

  # Select final Sanger sequences ----
  # First parse specimen voucher data
  sanger_seqs_with_voucher_data = parse_voucher(sanger_seqs_rogues_removed),
  # Join sequences across species, then select one set of sequences per species
  # Criteria for joining sequences across species:
  # - species is monophyletic, or
  # - all sequences for that species are from the same voucher, or
  # - all sequences for that species are from same publication
  # Criteria for selecting final set of sequences for each species (in order):
  # - 1: specimens with rbcL + any other gene
  # - 2: specimens with rbcL
  # - 3: specimens with longest combined non-rbcL genes
  sanger_accessions_selection = select_genbank_genes(
    sanger_seqs_with_voucher_data, mpcheck_monophy),

  # Download core set of plastid genes from plastomes ----
  # Download plastome metadata (accessions and species)
  plastome_metadata_raw = download_plastome_metadata(
    end_date = date_cutoff,
    outgroups = plastome_outgroups),
  # Resolve species names in plastome metadata
  # (will drop accession if name could not be resolved)
  # FIXME: add Lepisorus hederaceus (Christ) R.Wei & X.C.Zhang
  # and Elaphoglossum marginatum var. marginatum to World Ferns taxonomy
  plastome_metadata_raw_renamed = resolve_pterido_plastome_names(
    plastome_metadata_raw, plastome_outgroups, pc_ref_names, pteridocat
  ),
  # Download plastome sequences:
  # - genes
  target_plastome_accessions = unique(plastome_metadata_raw_renamed$accession),
  tar_target(
    plastome_genes_raw,
    fetch_fern_genes_from_plastome(
      genes = target_plastome_genes,
      accession = target_plastome_accessions),
    pattern = map(target_plastome_accessions),
    deployment = "main"),
  # - spacers
  # -- First download FASTA files for each accession (in seqtbl format)
  plastome_fasta = read_genbank(target_plastome_accessions),
  target_spacers = target_loci[str_detect(target_loci, "-")],
  # -- Use superCRUNCH to extract spacer region
  tar_target(
    fern_plastome_spacer_extract_res,
    extract_from_ref_blast(
      query_seqtbl = mutate(plastome_fasta, gene = target_spacers),
      ref = fern_ref_seqs,
      target = target_spacers,
      blast_flavor = "dc-megablast",
      other_args = c("-m", "span", "--threads", "4")
    ),
    pattern = map(target_spacers)
  ),
  # Combine plastome metadata and sequences, filter to best accession per taxon
  plastome_seqs_combined_filtered = select_plastome_seqs(
    plastome_genes_raw,
    plastome_metadata_raw_renamed,
    fern_plastome_spacer_extract_res),

  # Align spacers ----
  # Assign taxonomic clusters (by family) for aligning spacer regions
  tar_target(
    plastid_spacers_unaligned,
    assign_tax_clusters(
      sanger_accessions_selection,
      sanger_seqs_combined_filtered,
      plastome_seqs_combined_filtered,
      ppgi_taxonomy, plastome_metadata_raw_renamed,
      target_spacers
    ),
    pattern = map(target_spacers),
  ), # - configure groups for aligning in parallel
  tar_target(
    plastid_spacers_unaligned_grouped,
    plastid_spacers_unaligned %>%
      filter(cluster != "none") %>%
      group_by(target, cluster) %>%
      tar_group(),
    iteration = "group"
  ),
  # Align each cluster
  tar_target(
    plastid_spacers_aligned_clusters,
    align_seqs_tbl(plastid_spacers_unaligned_grouped),
    pattern = map(plastid_spacers_unaligned_grouped),
    iteration = "vector"
  ),
  # Trim each cluster, rename each sequence by taxon
  # (Use a very light threshold, to keep most gaps)
  plastid_spacers_aligned_trimmed_clusters = trim_spacers_by_cluster(
    plastid_spacers_aligned_clusters),
  # Also make overall alignment with one representative
  # per cluster to identify sequences needing reverse-complement
  tar_target(
    plastid_spacers_rep_align,
    align_rep_spacers(
      plastid_spacers_aligned_trimmed_clusters, # clusters
      plastid_spacers_unaligned, # singletons
      target_select = target_spacers,
      exclude_terms = "Anemiaceae"), # exclude Anemiaceae, too variable to align
    pattern = map(target_spacers)
  ),
  # Reverse-complement spacers
  plastid_spacers_aligned_trimmed_reversed_clusters = reverse_spacers(
    plastid_spacers_aligned_trimmed_clusters, plastid_spacers_rep_align
  ),
  # Merge subalignments
  tar_target(
    plastid_spacers_aligned_trimmed,
    merge_spacer_alignments(
      plastid_spacers_aligned_trimmed_reversed_clusters,
      n_threads = 10,
      target_select = target_spacers),
    pattern = map(target_spacers)
  ),

  # Align genes ----
  # Combine Sanger and plastome genes into single dataframe, group by gene
  tar_group_by(
    plastid_genes_unaligned,
    combine_sanger_plastome(
      # Exclude spacer regions (spacer regions have hyphen in name)
      sanger_accessions_selection %>%
        select(-contains("-")),
      sanger_seqs_combined_filtered %>%
        filter(str_detect(target, "-", negate = TRUE)),
      plastome_seqs_combined_filtered %>%
        filter(str_detect(target, "-", negate = TRUE))
      ),
    target),
  # Align sequences by gene
  tar_target(
    plastid_genes_aligned,
    align_seqs_tbl(plastid_genes_unaligned),
    pattern = map(plastid_genes_unaligned)
  ),
  # Trim alignments, rename each sequence by taxon
  plastid_genes_aligned_trimmed = trim_genes(plastid_genes_aligned),

  # Concatenate alignments ----
  # - tbl format
  plastid_alignment_tbl = bind_rows(
    plastid_genes_aligned_trimmed,
    plastid_spacers_aligned_trimmed),
  # - ape format
  plastid_alignment = do.call(
    ape::cbind.DNAbin,
    c(plastid_alignment_tbl$align_trimmed, fill.with.gaps = TRUE)),

  # Phylogenetic analysis ----
  # - gene trees
  tar_target(
    gene_trees,
    build_tree_from_alignment_df(plastid_alignment_tbl, program = "iqtree"),
    pattern = map(plastid_alignment_tbl)
  ),
  # - concatenated tree
  plastid_tree = jntools::iqtree(
    plastid_alignment,
    m = "GTR+I+G", bb = 1000, nt = "AUTO",
    redo = TRUE, echo = TRUE, wd = here::here("intermediates/iqtree")
  )

)
